{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "executable": "/usr/bin/env python3",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WolfgangWaltenberger/winterschool/blob/master/MCDropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9PAhenc0BvG",
        "colab_type": "text"
      },
      "source": [
        "Simple example for dropout as regularization, then Monte-Carlo dropout, with most of the code stolen from\n",
        "https://xuwd11.github.io/Dropout_Tutorial_in_PyTorch/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPCj9IEbgceN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## import all important libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import h5py\n",
        "from scipy.ndimage.interpolation import rotate\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import pymc3 as pm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9nrzUUtjdsS",
        "colab_type": "code",
        "outputId": "811ab320-8ad1-4f32-d3b1-3ceb65a5b160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "## load MNIST training and test data\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainset = datasets.MNIST(root='data/', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='data/', train=False, transform=transform)\n",
        "\n",
        "# Visualize 10 image samples in MNIST dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "# plot 10 sample images\n",
        "_,ax = plt.subplots(1,10)\n",
        "ax = ax.flatten()\n",
        "iml = images[0].numpy().shape[1]\n",
        "[ax[i].imshow(np.transpose(images[i].numpy(),(1,2,0)).reshape(iml,-1),cmap='Greys') for i in range(10)]\n",
        "[ax[i].set_axis_off() for i in range(10)]\n",
        "plt.show()\n",
        "print('label:',labels[:10].numpy())\n",
        "print('image data shape:',images[0].numpy().shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAAqCAYAAAAQ2Ih6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAUzklEQVR4nO2dfVBU1f/HP+ewUEAkBIFKCAsjSemo\nk0OOFiIjk6YzUCI+p4RWljE5hDg5loZZX5uy0jLccbR8oEgmrcmIETOysoFRojLFQKSB8GFdWHZ5\nWuD9+8Pf3i8Xdu/e3b275rf7mjnD7N1zz33vfXjfcz/ncy4MAKmoqKioeAd+swWoqKio/JtQTVdF\nRUXFi6imq6KiouJFVNNVUVFR8SKq6aqoqKh4EY2D729GagOzsUzVIUbVIUbVMZR/ihZVxyDUnq6K\nioqKF1FNV0VFRcWL/E+ablVVFU2YMIE450J5+umnqbe392ZL+9dSV1dHqampomPCOSez2Xyzpamo\neBWPmi4AOnnyJK1du5bS0tJo2bJlntwcEREdPXqUpk2bRrfffjvpdDrS6XT00EMPkU6no46ODo9v\nXy7nzp2j4OBg+v3332+2FI9TUVFBiYmJdPz4cWKMUUBAAAUEBBBjjH788cebLe9fA2OMfHx8hpTU\n1FRKT0+n0tJSslgsZLFYvK5t165dNrUN1Jydnf2PuoZdBoBUcYn+/n709/fjyJEjYIyBMYZHHnkE\ndXV1clZ3S0d7ezu+++47mEwmYVl5eTkYY2hra3OmKcX2hz1GjRqFzMxMRXW0tbXhP//5DwoKClBX\nV4eff/4Zvb29OHXqFDo6OtDR0YHr16+juLgYBQUFSE9Px549e2CxWBTVYaWrqwsPPPAAGGOYPHky\nqqqqsGXLFmzZsgWcc/z+++9ympGtw2Qy4erVq7h69Sq+/PJLLFmyRDgHrYVuDKogMDAQgYGB2L17\nt5zf75QOLyL72uWcQ6PRSJbk5GQkJydjwYIFaGpqQm9vr7taZGFP2+Dl2dnZOHLkiKI6DAYDqqur\nUVhYCM65qFjPFc45YmJi0NLSIvcn2dOhvOl2dHQgJycHOTk5Q072TZs2eeziliIvL8/rptvZ2Sn5\n/enTp8EYU9x0H3zwQdFJExgYiI0bN4JzjpUrV2LlypVgjA05uS5evKioDisFBQXgnCM+Ph7t7e0A\ngMuXL+Py5cu444478N1338lpRraO2NhY0e+aNWsWli9fjry8PPz666+isnz5cixfvhycc/z888+K\n6vAisq/dnJwch6Y7uOzdu9ddLQ4xGo2CuQYEBGDChAlCycnJwdatWzFhwgRERUVBo9EgKCgIRUVF\naG1tdVuH2WzG3LlzbRq8ddnA5UlJSbh8+bI7+0NZ0zWbzUhKShLuDlqtFuHh4YiPj0dwcDAYY9ix\nY4crQl3CaDTCaDTCz88PWVlZ6O/vd2Z1l3U0NTVh1apVknUqKyu9Yrq2CmNMVG/evHkwGAyK6gCA\n1tZWBAcHg3OOvLy8Id+fOnUKFy5ccNSMUzp8fHwwZswYbN26FQaDQfImbzKZYDKZwDlHcHAwenp6\nFNPhRWRfu319fdDr9cjNzRWVgIAAwVTmzJmDOXPmCJ99fX0RHh6OxsZGV7VI0tTUhMTERMHYJkyY\nYLdubW2t8ITkoK5sHenp6XZ71bZMV6PRQKvVOvpZUjqUM9329nakpKSAMYaxY8di7NixaG1tRXNz\nM9rb23Hp0iVMmjTJoRm5q2Mghw8fxuHDh8EYQ0NDg7Oru6xj/PjxOHbsmGQdq+nK6Om5bLrnz5/H\nJ598goaGBvT09Ailu7sbP/30E6qrq9HZ2Ym+vj45P8vp/ZGVlQXGGNLS0uS0LxdJHadPn8awYcNw\n4MABhw0NNF3OuVdN12g0oqioCEVFRTh48CAOHjyIM2fOALgRkpFpcvZ0OKWlrq4OFy5cwIULF9De\n3o729nY89dRTIqOJi4vDpUuXXNEiyaFDh0SGJ2W6VpQ03XHjxtk13RUrVtg0XY1G41CjhA6HkyNk\ns2zZMvr222+JiOiHH34gIqI777yThg0bRkREd9xxBw0fPlypzTmks7OTduzYIXyOjo722rZNJhPd\ndtttknWOHDlCABzWc5X777+foqKiKD4+3ub3kydP9sh2B8IYI8YYjRkzxuPbsjJx4kQ6duwY5ebm\n0qOPPkrBwcFe27Ytzpw5Qxs3bqTffvuNiG50chhj1N3dTS0tLcIyIqLAwEC6++67qa+vj8xmMwUF\nBRFj/82vX7ZsGb388suKa4yNjR2ybPv27ZScnExr1qwhvV5Ply5dopSUFPr2228pKipKke3q9XrK\nzMwkIqL+/n4iIiovL3e4XnJyMp04cYJqamrotddeo/Xr1yui58yZM6L9HRcXR4mJiURE9Oyzzyqy\nDSJSpqfb1taGyMhIjB07VrJHOWfOHISGhjqKrSrS062qqhJiya+//rorTTito7+/HxUVFQgNDcX3\n339vt57JZML48eMRHh4up3flUk935syZjtp1Fqf3x5NPPgnOOfLz872uo7u7G93d3ZINVVVVoaqq\nCpxzTJ8+XfFBoz179iAgIAA+Pj5C4ZyLPluX2Vs+eJlMHS4/HQ7m4sWLWLlypdDDi4iIkKrulI5r\n164N6WXq9XqHmrKysoT1tmzZ4pYOo9GIpUuX2nyyaGhoEA2kWcuMGTMcapTQ4X5P12g00qxZs6i5\nuZl2797tsEcZGhpKPj4+7m7WIa+88opwR87NzfX49ohu9HCnTZtGPj4+FBoaardeYWEh1dTUUERE\nBPn6+iq2/f7+furr6xMt+/TTT+nixYu0fft2YRn+v7dFdKN3VV5eTpGRkcS5chmE/f39ZDKZiIgo\nJCREsXbl4ufnJ/l9fX09PfTQQ8Lnffv2KX5eZmdnC/vZx8eHoqOjqa+vj6ZNm0bXr1+nBx54gIiI\n9u7dK9QZSF1dneiz1DnlKWJiYmj79u30xRdfkF6vJ4PBQB999BEtWbLE7f2l1+tFn9977z3hyViK\nhQsX0r59+4iI6J133qGMjAwaPXq0SxqCgoLo448/HrK8traW0tLShGvC+vexxx4jnU7n0rYE7Lmx\n1N1hIDt37gRjDJMmTUJXV5fdevX19fDz8/NKTPfcuXPQaDSYO3cu5s6d6+zqLunQ6/V47rnnQEQI\nCwuTbPitt94SsjmU1HH16lVERESAc46RI0ciPz8fgYGBNgfSBi978803hewCd3UANwZVrW07im8D\nNwbdysrKUFZWhqtXryqmwxb19fVIS0sT9D3zzDMOe8Wu6BjYU3311VedaryyslK0vsRglkd7ulb2\n798vimk2NzfL1WKXgfHUMWPGoLa2VpaW6upqkZaamhq3dAwmMzMTkZGRNgfS7PSs7WHz2Lhluq2t\nrRg9ejQYYw7TKGpra8EY84rpvvrqqwgJCcH58+dx/vx5Z1d3SYd1wI4xZuskEGFNYTt06JCiOs6e\nPSuZtZCQkICEhAS88MIL+OOPP3Do0CFkZWUJBvT8888rogMALBYLHn74YTDGJMML165dw/z580Wp\nhSNHjkRTU5MiOoAbYZ+uri50dXVh1apVCAgIAOccERERiIiIQHt7Ozo7O53N1XWow3r+SaQ22eTE\niRNCjijnHNHR0di5c6czOhQ33Z6eHlRVVQnms2DBArla7DLQdJ0YOPS46Q4eXPtHme7ChQtBREhK\nSnKYl1pYWAgfHx+pi0lKqGzOnj2LgIAAzJo1y5nV3NYxb948wTQGXmRmsxm1tbWora1FWVkZvv76\nawQEBCAuLs7hPnNWhy3T9fPzw+nTp2EwGITJEYOpr68H5xz+/v74+++/3dZhxRrTfeGFF0TLa2pq\nUFNTg/T0dNx1113QaDSYPn063nrrLaxYsQKMMSQkJNiLsTqlo6OjA5999hnCw8MxcuRIyZtSUlKS\nkEEgA48YXWNjI4KCgoSYblZWlqOsAa+YLnBjX86bN0+I7f72229ytAzBbDYjKytLtO+dgQbFWH/5\n5ReXdNhDynQTEhKwdOlSbN++XZZUW+V/8t0LKioqKv9Y7Lmxo7tDW1sb4uLiHPWORHWXLFni6t1B\nNh9//DEYY9DpdDCbzTCbzbbuyIrrOHDgADQaDRhjQlK5r6+v6G458BE6KyvLIzoWLVoErVaL3Nxc\nFBcXy8o9ra+vF3QdPHhQER3AjTCP9be3trbCYrHg0KFD8Pf3h7+/v/CIv2vXLtF68+fPB+ccVVVV\nbut47rnnBA3x8fFYt24dGhoa0NDQIDz+r1mzBmvWrIGvry9CQkKwdu1aORNpFO9dlpWVYfLkyUIc\n9/nnn5eTUaFIT7ezsxM6nW5IsYZdzp49i9bWViQlJQm9vtLSUjlahjA4POBE3iuAoVOGlQ4vGI1G\nTJo0acg04IFl8eLFcppSNrxQWFgIxpgsI3WmrrM6BmIwGBAaGopZs2Zhw4YNIpP74IMP5Dbjso66\nujp89NFHou2Gh4dj9erVQhkxYoRHTRcArl+/LrdtAMCPP/4Izjl8fX2xbt06xXTo9XoEBQWBc44N\nGzaIBtc451iwYIHNFMO1a9eCc47169e7reP9999HTEwMvvzyS4c3IKPRiOnTp4NzjpycHEcxXsVM\n98SJEzhx4oQQVvDz88Po0aPlhOLs6bCp5ddff0VZWRni4+OHFK1WC41Gg6ioKERFRQkDSYsWLcKK\nFSsQGhqKUaNGCUYXFhbm8mO9q6bb2dmJ1atXi0w3Ly/P1nF1+9g0NTXh888/tzs5Ij4+Xs7An3Km\na7FYkJmZCcYYXnzxRcmttre3IyYmBkFBQaioqJDze13eYW+//TYYY7j99tuF3Mvp06cjNTUVsbGx\ncmOobuno7e1FZ2enUAaOivf29iI1NRWMMVRWVnpUh1x6enqQmpoKzjmGDRumuI7c3FxwzhESEoKT\nJ0+Cc46wsDCEhYXZzcmMjIxUrKfrLCaTSdgfR48elaqqiA5rloIbmQ6yr11b5jG4aLVaaLVaxMTE\nSNZ77733kJubK0fLEFw13cGz1yIiInDq1Cm5+8Ql9Ho99Ho9tm7dioSEBFGsNzIy0tEgqXKm29bW\nhuHDh4MxJjl3vqmpCWlpaWCM4fDhw3J/p8tml5CQAMYY/P39kZeXB4vFAovFgu+//x6MMVmJ1+7q\nkKKlpUUYnTebzTdNx0AMBoOo91leXq6ojtbWVoSEhICIhrwA6Y033hhS32QygYjg5+dn79zy6P4A\nbgz0WEMNNnpziukYmKVgfYTdtm2bs80oarqbNm3Cpk2bRINJtsqZM2dsPaXI0mE2m5Gdne2U6RqN\nRiQmJsqdMuzWsTl+/LjNXqwLkzmUM10AeOqpp+ya7pUrV3DlyhUsX74cjDEkJSXJmbctJdQhJSUl\nwsX85ptvDm2UCC+99JJcDS7rkOL48eNyX/rjUR1WTCaT0BPlnOPll1+WOolc1mF9xac1rlpSUoKS\nkhLRiW2xWKDX6zF16lQwxrB06VLFdTiDNR4t0et0S0dZWZkoS4Fzjh07djg7K86eDqdNd+LEidBo\nNCgsLERhYSG0Wi1WrFgxpN6BAwdw7do1e6EX2ftkYLyfc+7w3Shjx44V6g4fPhxLly6Vyit361wN\nDg5GQkLCkDS21atX/zNMd/Aj2KlTpzBixAghdrlw4UKvPNavWrUKjDEUFBTYfIHLiBEjEBoaKsQ7\nu7u7UVpaKvUIqfjFnZ2dDcYY9uzZ48xqHjGZ2tpapKSkCCfywoULJSe3uKtj7969wrYSExORmJiI\no0ePorKyEpWVlXj33XfBOUd6ejr2798vNVnBK6b77LPPesx0Ozo6hAGzhIQEbNu2Ddu2bXPFcO3p\nsKnF+v5gq3FER0dj8eLF0Gg0wmsuU1JSkJKSguLi4iGGGxgYKDm9Xa4O4MYrP+XESFtaWlBQUIDw\n8HChrsQN2WkdA6murhbdCHbt2oXq6mpUV1cPSXEjIiQmJroyoch10921a5fwYuo//vgDP/30E6ZM\nmSJ6XMrMzHR0IcsVKklPT49wd7I3m6mkpESY+aLT6YSTbcOGDYrpcISvr69XTPfcuXPYvHnzkOV/\n/vkn/vzzTyxYsEDIHrDGEF0cJZdNb28vfvnlF2i1Wpuz40JCQmAwGDymw2w244svvpCVzdHS0iL0\nZr766itFdZw+fRqzZ8+Gj48PRowYgWvXrslZTQqnrl2j0YiCggIsWrTIZo936tSpmDp1KqZMmSJa\nnpKSIvrHAE5osYnZbBa9QtIaIx03bpyoREdHi3TExsY6MjqndAxk4Dsd7OXpWktiYqKrcw5cN93e\n3l5kZGQIMVRrupQ1VvfGG284+6o8KaGS9PX14f3333c4E6ykpETogc+YMQNFRUWK6nCEt0w3NTUV\nU6ZMQXNzMxobG5Gfn4/8/HwEBwcjODhYlAIzadIkj+mwRUdHB4qLi1FcXIz8/HyMHz8eU6dORUlJ\niUd1/PXXX+CcY/PmzTAYDKKYujX239HRgYqKCuFiS01NlXpKc0lHUVGRy1ODndDhUEtnZyeam5vR\n3NyMjIwMzJw5U8hg0Gg0uO+++xAbG4uZM2di3rx5cozOnha7mM1mZGRkiB7XbZmeddBsy5Ytcl8g\n7tKxsaXBnulKZPk40uHejLTy8nJotVowxjBlyhRs27bN2VCCXKE3A8V16HQ6r5jumjVrJGdeWXuX\nGRkZzgwu3tLHRa/XIywsTNgHWq0WTzzxBJ544gnMnj0baWlpuO+++4TvJ06c6Oi/aTilo6urC48/\n/rhww5s9e7Yc2XJw6dq1RWNjI0pLS1FaWoorV644NTVXQoskra2tSE1NxYwZM4YMrllNb+PGjbLf\ny+CqDgDYvHmzKA/ZlukmJyc7MxXY5rFhACTnTnhyYoYdmI1lqg4xkjq6urqorKyMPvvsM2psbKST\nJ0/SvffeS4sXLyYiom+++YbWr19PM2bMcOZNUbfs/rBiNBpJp9NRfX09ffjhhzbrREdHU1ZWFr34\n4ovk7++vmA6j0Uh33XUXAaC4uDg6duwYjRo1So5sR9jSIanFg9zy58iVK1do8uTJ9NdffxHRf9/z\nyzmn0tJSGjduHIWHh7ujQzVdCVQdYlQdYlwy3XvuuYcqKiqUMlx7OiS1eJBb8th4EJvHRn33goqK\nFzh+/DgREa1bt05Jw1W5BVF7uvZRdYhRdYhxSkd3dzcdPnyY5s+f7w0dklo8yC15bDyIS+EFFRUV\nFRUFUcMLKioqKl5ENV0VFRUVL6KaroqKiooXUU1XRUVFxYuopquioqLiRVTTVVFRUfEi/wfFvhG3\ndoKC1wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "label: [0 2 4 5 6 3 7 2 0 3]\n",
            "image data shape: (1, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NCjDJOO_g7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## a helper class to flatten tensors\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "## a ConvNet, with  2 convolutional layers, one dense layer, dropout rate configurable\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, droprate=0.5):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.model = nn.Sequential()\n",
        "        self.model.add_module('conv1', nn.Conv2d(1, 20, kernel_size=5, padding=2))\n",
        "        self.model.add_module('dropout1', nn.Dropout2d(p=droprate))\n",
        "        self.model.add_module('maxpool1', nn.MaxPool2d(2, stride=2))\n",
        "        self.model.add_module('conv2', nn.Conv2d(20, 50, kernel_size=5, padding=2))\n",
        "        self.model.add_module('dropout2', nn.Dropout2d(p=droprate))\n",
        "        self.model.add_module('maxpool2', nn.MaxPool2d(2, stride=2))\n",
        "        self.model.add_module('flatten', Flatten())\n",
        "        self.model.add_module('dense3', nn.Linear(50*7*7, 500))\n",
        "        self.model.add_module('relu3', nn.ReLU())\n",
        "        self.model.add_module('dropout3', nn.Dropout(p=droprate))\n",
        "        self.model.add_module('final', nn.Linear(500, 10))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPw6Ca5F_yM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## sklearn-like interface, make sure we keep track of all the test results\n",
        "class LeNetClassifier:\n",
        "    def __init__(self, droprate=0.5, batch_size=128, max_epoch=300, lr=0.01):\n",
        "        self.batch_size = batch_size\n",
        "        self.max_epoch = max_epoch\n",
        "        self.lr = lr\n",
        "        self.model = LeNet(droprate)\n",
        "        # self.model.cuda()\n",
        "        self.criterion = nn.CrossEntropyLoss().cuda()\n",
        "        self.optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
        "        self.loss_ = []\n",
        "        self.test_error = []\n",
        "        self.test_accuracy = []\n",
        "        \n",
        "    def fit(self, trainset, testset, verbose=True):\n",
        "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=self.batch_size, shuffle=True)\n",
        "        testloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
        "        X_test, y_test = iter(testloader).next()\n",
        "        # X_test = X_test.cuda()\n",
        "        print(self.model)\n",
        "        for epoch in range(self.max_epoch):\n",
        "            running_loss = 0\n",
        "            for i, data in enumerate(trainloader, 0):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                running_loss += loss.data[0]\n",
        "            self.loss_.append(running_loss / len(trainloader))\n",
        "            if verbose:\n",
        "                print('Epoch {} loss: {}'.format(epoch+1, self.loss_[-1]))\n",
        "            y_test_pred = self.predict(X_test).cpu()\n",
        "            self.test_accuracy.append(np.mean(y_test == y_test_pred))\n",
        "            self.test_error.append(int(len(testset)*(1-self.test_accuracy[-1])))\n",
        "            if verbose:\n",
        "                print('Test error: {}; test accuracy: {}'.format(self.test_error[-1], self.test_accuracy[-1]))\n",
        "        return self\n",
        "    \n",
        "    def predict(self, x):\n",
        "        model = self.model.eval()\n",
        "        outputs = model(Variable(x))\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        model = self.model.train()\n",
        "        return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiZusIMY_6fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## now train! Dont train per default (takes too long)\n",
        "do_train = False\n",
        "if do_train:\n",
        "  # Define networks\n",
        "  lenet1 = [LeNetClassifier(droprate=0, max_epoch=1500),\n",
        "            LeNetClassifier(droprate=0.5, max_epoch=1500)]\n",
        "        \n",
        "  # Training, set verbose=True to see loss after each epoch.\n",
        "  [lenet.fit(trainset, testset,verbose=False) for lenet in lenet1]\n",
        "\n",
        "  # Save torch models\n",
        "  for ind, lenet in enumerate(lenet1):\n",
        "    torch.save(lenet.model, 'mnist_lenet1_'+str(ind)+'.pth')\n",
        "    # Prepare to save errors\n",
        "    lenet.test_error = list(map(str, lenet.test_error))\n",
        "\n",
        "  # Save test errors to plot figures\n",
        "  open(\"lenet1_test_errors.txt\",\"w\").write('\\n'.join([','.join(lenet.test_error) for lenet in lenet1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL4Z1prJAZ3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "0f5053f2-00a0-4ca2-d8c0-1c20bccec105"
      },
      "source": [
        "# Load saved models to CPU\n",
        "lenet1_models = [torch.load('mnist_lenet1_'+str(ind)+'.pth', map_location={'cuda:0': 'cpu'}) for ind in [0,1]]\n",
        "\n",
        "# Load saved test errors to plot figures.\n",
        "lenet1_test_errors = [error_array.split(',') for error_array in \n",
        "                      open(\"lenet1_test_errors.txt\",\"r\").read().split('\\n')]\n",
        "lenet1_test_errors = np.array(lenet1_test_errors,dtype='f')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ce2c5a4ff65c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlenet1_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_lenet1_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load saved test errors to plot figures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m lenet1_test_errors = [error_array.split(',') for error_array in \n\u001b[1;32m      5\u001b[0m                       open(\"lenet1_test_errors.txt\",\"r\").read().split('\\n')]\n",
            "\u001b[0;32m<ipython-input-9-ce2c5a4ff65c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlenet1_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_lenet1_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load saved test errors to plot figures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m lenet1_test_errors = [error_array.split(',') for error_array in \n\u001b[1;32m      5\u001b[0m                       open(\"lenet1_test_errors.txt\",\"r\").read().split('\\n')]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist_lenet1_0.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JidyS5k5B0Fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}